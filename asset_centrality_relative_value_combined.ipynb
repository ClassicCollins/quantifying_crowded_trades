{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Get the Market Capitalization\n",
        "def get_market_cap(ticker):\n",
        "    try:\n",
        "        stock_data = yf.Ticker(ticker)\n",
        "        market_cap = stock_data.info.get('marketCap')\n",
        "\n",
        "        if market_cap is not None:\n",
        "            return market_cap\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {ticker}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Get the Price-to-Book ratio\n",
        "def get_price_to_book(ticker):\n",
        "    try:\n",
        "        stock_data = yf.Ticker(ticker)\n",
        "        book_value = stock_data.info.get('bookValue')\n",
        "        price = stock_data.history(period='1d')['Close'].iloc[-1]\n",
        "\n",
        "        if book_value is not None and price is not None and book_value != 0:\n",
        "            price_to_book = price / book_value\n",
        "            return price_to_book\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {ticker}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Calculate the five-year average P/B\n",
        "def calculate_five_year_average(ticker):\n",
        "    end_date = datetime.now()\n",
        "    start_date = end_date - timedelta(days=5 * 365)  # Five years ago\n",
        "\n",
        "    try:\n",
        "        stock_data = yf.Ticker(ticker)\n",
        "        historical_data = stock_data.history(start=start_date, end=end_date)['Close']\n",
        "        book_value = stock_data.info.get('bookValue')\n",
        "\n",
        "        if book_value is not None and not historical_data.empty:\n",
        "            pb_ratios = historical_data / book_value\n",
        "            five_year_average = pb_ratios.mean()\n",
        "            return five_year_average\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {ticker}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Download Financial assets From S&P500 Financial Sector\n",
        "def retrieve_financial_sector_assets():\n",
        "    data = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
        "    table = data[0]\n",
        "    financial_sector = table[table['GICS Sector'] == 'Financials']  # XLF\n",
        "    financial_sector_assets = financial_sector['Symbol'].tolist()\n",
        "    return financial_sector_assets\n",
        "\n",
        "# Select the top 10 assets based on ROI\n",
        "def get_top_assets(asset_data, start, end):\n",
        "    df_asset = yf.download(asset_data, start=start, end=end)['Adj Close']\n",
        "    roi = (df_asset.iloc[-1] - df_asset.iloc[0]) / df_asset.iloc[0]\n",
        "    top_10_ROI = roi.sort_values(ascending=False).head(10)\n",
        "    roi_tickers = top_10_ROI.index.tolist()\n",
        "    df_prices = yf.download(roi_tickers, start=start, end=end)['Adj Close']\n",
        "    df_assets = df_prices.pct_change().dropna()\n",
        "    return df_assets\n",
        "\n",
        "# Calculate Centrality\n",
        "def download_sector_data(symbols, start_date, end_date):\n",
        "    df_sectors = yf.download(symbols, start=start_date, end=end_date)['Adj Close']\n",
        "    df_sectors = df_sectors.pct_change().dropna()\n",
        "    return df_sectors\n",
        "\n",
        "def preprocess_data(df_sectors):\n",
        "    scaler = StandardScaler()\n",
        "    df_sectors_scaled = scaler.fit_transform(df_sectors)\n",
        "    return df_sectors_scaled\n",
        "\n",
        "def calculate_weight(market_cap):\n",
        "    weights = [cap / np.sum(market_cap) for cap in market_cap]\n",
        "    return weights\n",
        "\n",
        "def calculate_weighted_df(df_sectors, market_cap):\n",
        "    weights = calculate_weight(market_cap)\n",
        "    sector_weights = dict(zip(df_sectors.columns, [weight * 100 for weight in weights]))\n",
        "\n",
        "    weighted_df = df_sectors.copy()\n",
        "\n",
        "    for sector in df_sectors.columns:\n",
        "        weighted_df.loc[:, sector] *= np.sqrt(sector_weights[sector])\n",
        "\n",
        "    return weighted_df\n",
        "\n",
        "def calculate_centrality_score(X, n=2):\n",
        "    pca_model = PCA(n_components=n)\n",
        "    pca_model.fit(X)\n",
        "    EV = pca_model.components_\n",
        "    AR = pca_model.explained_variance_ratio_\n",
        "\n",
        "    C_list = []\n",
        "    for i in range(X.shape[1]):\n",
        "        C_num = sum(AR[j] * abs(EV[j][i]) / sum(abs(EV[j][k]) for k in range(X.shape[1])) for j in range(n))\n",
        "        C_denom = sum(AR[j] for j in range(n))\n",
        "        C_list.append(C_num / C_denom)\n",
        "\n",
        "    return C_list\n",
        "\n",
        "# Calculate Relative Value\n",
        "def fetch_sector_data(symbols, start_date, end_date):\n",
        "    df_sectors_prices = yf.download(symbols, start=start_date, end=end_date)['Adj Close']\n",
        "    df_sectors = df_sectors_prices.pct_change().dropna()\n",
        "    return df_sectors\n",
        "\n",
        "# Normalized by dividing its current p/b value with the asset's 5-year_p/b\n",
        "def calc_normalize_price(price_book, five_year_ave_price_book):\n",
        "    normalized_prices = [pb / five_pb for pb, five_pb in zip(price_book, five_year_ave_price_book)]\n",
        "    return normalized_prices\n",
        "\n",
        "def calc_asset_weight(normalized_price, five_year_ave_price_book):\n",
        "    weights = [np * five_pb / sum(five_year_ave_price_book) for np, five_pb in zip(normalized_price, five_year_ave_price_book)]\n",
        "    return weights\n",
        "\n",
        "def calculate_relative_measure(normalized_prices, weights):\n",
        "    normalized_prices = np.nan_to_num(normalized_prices, nan=0.0)\n",
        "    weighted_average = np.dot(weights, normalized_prices)\n",
        "    relative_measure = np.zeros_like(normalized_prices)\n",
        "    nonzero_indices = (weighted_average != 0)\n",
        "    relative_measure[nonzero_indices] = normalized_prices[nonzero_indices] / weighted_average[nonzero_indices]\n",
        "    return relative_measure\n",
        "\n",
        "def create_relative_scores_df(symbols, normalized_prices, weights):\n",
        "    relative_measure = calculate_relative_measure(normalized_prices, weights)\n",
        "    relative_scores = dict(zip(symbols, [np.around(r, 2) for r in relative_measure]))\n",
        "    for asset in relative_scores:\n",
        "        relative_scores[asset] = [relative_scores[asset]]\n",
        "    scores_df = pd.DataFrame(data=relative_scores, index=['Relative_score'])\n",
        "    scores_df = scores_df.transpose()\n",
        "    return scores_df\n",
        "\n",
        "# Combine Centrality and Relative Value\n",
        "def combine_centrality_relative_value(weighted_df, symbols, normalized_prices, weights):\n",
        "    centrality_scores = calculate_centrality_score(weighted_df)\n",
        "    scores_df = create_relative_scores_df(symbols, normalized_prices, weights)\n",
        "\n",
        "    centrality_df = pd.DataFrame(data=centrality_scores, columns=['Centrality'], index=symbols)\n",
        "    relative_df = create_relative_scores_df(symbols, normalized_prices, weights)\n",
        "\n",
        "    combined_scores_df = pd.concat([centrality_df, relative_df], axis=1)\n",
        "    print(combined_scores_df)\n",
        "\n",
        "    combined_scores_df.index.name = 'Ticker'\n",
        "    return combined_scores_df\n",
        "\n",
        "# Construct portfolios for assets with no bubbles, bubbles rising, & bubbles falling\n",
        "def construct_portfolios(df_sectors, symbols, normalized_prices, weights):\n",
        "    combined_scores_df = combine_centrality_relative_value(weighted_df, symbols, normalized_prices, weights)\n",
        "\n",
        "    try:\n",
        "        top_crowded = combined_scores_df.sort_values(by='Centrality', ascending=False).head(5).index\n",
        "        top_overvalued = combined_scores_df.sort_values(by='Relative_score', ascending=False).head(5).index\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "    if top_crowded.empty or top_overvalued.empty:\n",
        "        print(\"Error: Top crowded or top overvalued is empty.\")\n",
        "        return None, None, None\n",
        "\n",
        "    print(\"Top Five Crowded Sectors:\", top_crowded)\n",
        "    print(\"Top Five Overvalued Sectors:\", top_overvalued)\n",
        "\n",
        "    next_day_returns = df_sectors.shift(-1)\n",
        "\n",
        "    no_bubble_portfolio = combined_scores_df[~combined_scores_df.index.isin(top_crowded.union(top_overvalued))]\n",
        "    bubble_run_up_portfolio = combined_scores_df[combined_scores_df.index.isin(top_crowded) & ~combined_scores_df.index.isin(top_overvalued)]\n",
        "    bubble_sell_off_portfolio = combined_scores_df[combined_scores_df.index.isin(top_crowded) & combined_scores_df.index.isin(top_overvalued)]\n",
        "\n",
        "    return no_bubble_portfolio, bubble_run_up_portfolio, bubble_sell_off_portfolio, next_day_returns\n",
        "\n",
        "# Impute Values below:\n",
        "if __name__ == \"__main__\":\n",
        "    # Input the timeframe\n",
        "    start_date = \"2018-01-01\"\n",
        "    end_date = \"2023-01-01\"\n",
        "    financial_sector_assets = retrieve_financial_sector_assets()\n",
        "    df_financial_assets = get_top_assets(financial_sector_assets, start=start_date, end=end_date)\n",
        "\n",
        "    # Allow symbols of top 10 assets or input other 10 preferred asset tickers as symbols\n",
        "    symbols = df_financial_assets.columns.tolist()\n",
        "    # symbols = ['AJG', 'AON', 'BRO', 'BX', 'MA', 'MMC', 'MSCI', 'NDAQ', 'PGR', 'WRB']\n",
        "\n",
        "    market_cap = [get_market_cap(ticker) for ticker in symbols]\n",
        "    price_book = [get_price_to_book(ticker) for ticker in symbols]\n",
        "    five_year_ave_price_book = [calculate_five_year_average(ticker) for ticker in symbols]\n",
        "    sector_data = download_sector_data(symbols, start_date, end_date)\n",
        "    scaled_data = preprocess_data(sector_data)\n",
        "    df_sectors = download_sector_data(symbols, start_date, end_date)\n",
        "    weighted_df = calculate_weighted_df(df_sectors, market_cap)\n",
        "    weighted_scores = calculate_centrality_score(weighted_df)\n",
        "    df_sectors = fetch_sector_data(symbols, start_date, end_date)\n",
        "    normalized_prices = calc_normalize_price(price_book, five_year_ave_price_book)\n",
        "    weights = calc_asset_weight(normalized_prices, five_year_ave_price_book)\n",
        "    relative_measure = calculate_relative_measure(normalized_prices, weights)\n",
        "    scores_df = create_relative_scores_df(symbols, normalized_prices, weights)\n",
        "    df_sectors.index.names = ['Date']\n",
        "\n",
        "    no_bubble_portfolio, bubble_run_up_portfolio, bubble_sell_off_portfolio, next_day_returns = construct_portfolios(\n",
        "        df_sectors, symbols, normalized_prices, weights)\n",
        "\n",
        "    print(\"***No Bubble Portfolio***:\")\n",
        "    print(no_bubble_portfolio)\n",
        "    print(\"\\n***Bubble Run-up Portfolio***:\")\n",
        "    print(bubble_run_up_portfolio)\n",
        "    print(\"\\n***Bubble Sell-off Portfolio***:\")\n",
        "    print(bubble_sell_off_portfolio)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I14YjwYvZf-H",
        "outputId": "2f262ed0-e2db-45bd-a4ac-3146bb37d1b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%%**********************]  72 of 72 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['BRK.B']: Exception('%ticker%: No timezone found, symbol may be delisted')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[*********************100%%**********************]  10 of 10 completed\n",
            "[*********************100%%**********************]  10 of 10 completed\n",
            "[*********************100%%**********************]  10 of 10 completed\n",
            "[*********************100%%**********************]  10 of 10 completed\n",
            "      Centrality  Relative_score\n",
            "AJG     0.061458            1.22\n",
            "AON     0.067538            0.93\n",
            "BRO     0.040818            1.03\n",
            "BX      0.210663            1.08\n",
            "MA      0.304872            0.89\n",
            "MMC     0.080872            1.03\n",
            "MSCI    0.079732            0.88\n",
            "NDAQ    0.052101            0.81\n",
            "PGR     0.066579            1.15\n",
            "WRB     0.035368            0.99\n",
            "Top Five Crowded Sectors: Index(['MA', 'BX', 'MMC', 'MSCI', 'AON'], dtype='object', name='Ticker')\n",
            "Top Five Overvalued Sectors: Index(['AJG', 'PGR', 'BX', 'BRO', 'MMC'], dtype='object', name='Ticker')\n",
            "***No Bubble Portfolio***:\n",
            "        Centrality  Relative_score\n",
            "Ticker                            \n",
            "NDAQ      0.052101            0.81\n",
            "WRB       0.035368            0.99\n",
            "\n",
            "***Bubble Run-up Portfolio***:\n",
            "        Centrality  Relative_score\n",
            "Ticker                            \n",
            "AON       0.067538            0.93\n",
            "MA        0.304872            0.89\n",
            "MSCI      0.079732            0.88\n",
            "\n",
            "***Bubble Sell-off Portfolio***:\n",
            "        Centrality  Relative_score\n",
            "Ticker                            \n",
            "BX        0.210663            1.08\n",
            "MMC       0.080872            1.03\n"
          ]
        }
      ]
    }
  ]
}